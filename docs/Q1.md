# Full-Stack Blog Admin System - Interview Questions & Answers

This document contains 50 interview questions covering the five services: Frontend (React), Auth Service (Spring Boot), Blog Service (Spring Boot), Database (PostgreSQL), and Blog Cache (Redis).

---

## Table of Contents

1. [Frontend (React/TypeScript)](#frontend-reacttypescript) - Questions 1-10
2. [Auth Service (Spring Boot)](#auth-service-spring-boot) - Questions 11-20
3. [Blog Service (Spring Boot)](#blog-service-spring-boot) - Questions 21-30
4. [Database (PostgreSQL/JPA)](#database-postgresqljpa) - Questions 31-37
5. [Blog Cache (Redis)](#blog-cache-redis) - Questions 38-43
6. [Architecture & System Design](#architecture--system-design) - Questions 44-50

---

## Frontend (React/TypeScript)

### Question 1: How does this application handle authentication state management?

**Answer:**

The application uses React Context API via `AuthContext.tsx` to manage authentication state globally. The implementation includes:

```typescript
// AuthContext provides:
- isAuthenticated: boolean  // Whether user is logged in
- isLoading: boolean        // Auth verification in progress
- login(): void             // Sets isAuthenticated to true
- logout(): void            // Clears auth state
```

**Key architectural decisions:**

1. **JWT stored in HttpOnly cookies** - Not in localStorage/sessionStorage. This prevents XSS attacks from stealing tokens since JavaScript cannot access HttpOnly cookies.

2. **Auto-verification on mount** - The context calls `/auth/me` endpoint on app startup to verify if the stored cookie contains a valid JWT.

3. **Event-driven logout** - The API interceptor dispatches `auth:logout` custom events when receiving 401 responses, which the AuthContext listens for to synchronize state.

4. **Centralized access** - Components use `useAuth()` hook to access auth state without prop drilling.

---

### Question 2: Explain how the PrivateRoute component works and why it's necessary.

**Answer:**

`PrivateRoute` is a route guard component that protects authenticated-only routes:

```tsx
const PrivateRoute = ({ children }) => {
  const { isAuthenticated, isLoading } = useAuth();

  if (isLoading) return <LoadingSpinner />;
  if (!isAuthenticated) return <Navigate to="/login" />;
  return children;
};
```

**Why it's necessary:**

1. **Client-side protection** - Prevents unauthenticated users from accessing protected UI components
2. **UX consideration** - Shows loading state while verifying auth status to prevent flash of login page
3. **Declarative routing** - Enables clean route definitions in App.tsx:

```tsx
<Route path="/articles" element={
  <PrivateRoute><ArticleList /></PrivateRoute>
} />
```

**Important caveat:** This is UI protection only. The backend must still validate JWT on every API request since client-side checks can be bypassed.

---

### Question 3: How does the application prevent XSS attacks?

**Answer:**

Multiple layers of XSS protection are implemented:

1. **React's default escaping** - JSX automatically escapes values, so `{userInput}` is safe by default.

2. **DOMPurify for HTML content** - When rendering user-generated HTML (article content):
   ```typescript
   import DOMPurify from 'dompurify';
   const sanitized = DOMPurify.sanitize(content);
   ```

3. **HttpOnly cookies for JWT** - Tokens cannot be stolen via `document.cookie` since the HttpOnly flag prevents JavaScript access.

4. **Custom `escapeHtml()` utility** - Used in ArticleList for additional sanitization of displayed text.

5. **Input validation** - Form inputs have maxLength constraints that limit attack payload size.

6. **Content Security Policy** - Could be added via Nginx headers to restrict script sources (not currently implemented).

---

### Question 4: Explain the CSRF protection mechanism in the frontend.

**Answer:**

The application implements double-submit cookie pattern for CSRF protection:

**How it works:**

1. Server sets `XSRF-TOKEN` cookie (readable by JavaScript, unlike HttpOnly cookies)
2. Frontend reads this cookie and includes value in `X-XSRF-TOKEN` header
3. Server validates that header matches cookie value

**Implementation in `api.ts`:**

```typescript
api.interceptors.request.use((config) => {
  if (['post', 'put', 'delete', 'patch'].includes(config.method)) {
    const csrfToken = getCookie('XSRF-TOKEN');
    if (csrfToken) {
      config.headers['X-XSRF-TOKEN'] = csrfToken;
    }
  }
  return config;
});
```

**Why this works:** An attacker's site cannot read cookies from another domain (Same-Origin Policy), so they cannot forge the header even if they can trigger cookie-authenticated requests.

**Note:** The Spring backend currently has CSRF disabled since JWT-based stateless auth is inherently CSRF-resistant (attackers can't read the JWT from cookies to include in requests).

---

### Question 5: What is code splitting and how is it implemented here?

**Answer:**

Code splitting divides the JavaScript bundle into smaller chunks loaded on demand, improving initial page load time.

**Implementation using React.lazy and Suspense:**

```tsx
// Lazy-loaded components
const Login = lazy(() => import('./pages/Login'));
const ArticleList = lazy(() => import('./pages/ArticleList'));
const ArticleForm = lazy(() => import('./pages/ArticleForm'));

// In App.tsx
<Suspense fallback={<LoadingSpinner />}>
  <Routes>
    <Route path="/login" element={<Login />} />
    <Route path="/articles" element={<ArticleList />} />
  </Routes>
</Suspense>
```

**How it works:**

1. `lazy()` creates a component that loads its code only when first rendered
2. `Suspense` shows fallback UI while the chunk is loading
3. Webpack/bundler creates separate chunk files (e.g., `Login.chunk.js`)

**Benefits:**
- Initial bundle only includes core routing code
- Page-specific code loads when user navigates there
- Reduces Time to Interactive (TTI) metric

---

### Question 6: How does the Axios interceptor handle 401 errors?

**Answer:**

The response interceptor in `api.ts` provides centralized error handling for authentication failures:

```typescript
api.interceptors.response.use(
  (response) => response,
  (error) => {
    if (error.response?.status === 401) {
      // Dispatch custom event for AuthContext to handle
      window.dispatchEvent(new CustomEvent('auth:logout'));
    }
    return Promise.reject(error);
  }
);
```

**Flow:**
1. Any API call receives 401 (Unauthorized)
2. Interceptor catches error before it reaches component
3. Dispatches `auth:logout` custom event
4. AuthContext listener receives event, sets `isAuthenticated = false`
5. PrivateRoute detects this change, redirects to `/login`
6. Original error is still rejected so component can show error message

**Why custom events?** Axios instance is separate from React component tree, so it can't directly access Context. Custom events provide decoupled communication.

---

### Question 7: Explain the form validation strategy using react-hook-form.

**Answer:**

The application uses react-hook-form for declarative, performant form validation:

**Example from ArticleForm:**

```tsx
const { register, handleSubmit, formState: { errors } } = useForm<ArticleDto>();

<input
  {...register('title', {
    required: 'Title is required',
    maxLength: { value: 200, message: 'Title must be under 200 characters' }
  })}
/>
{errors.title && <span className="error">{errors.title.message}</span>}
```

**Key features used:**

1. **register()** - Connects input to form state without controlled components
2. **Validation rules** - Required, minLength, maxLength, pattern (regex)
3. **Error messages** - Accessed via `formState.errors`
4. **handleSubmit()** - Only calls submit function if validation passes

**Why react-hook-form over controlled components?**
- Uncontrolled inputs = fewer re-renders = better performance
- Built-in validation = less boilerplate
- TypeScript support with generics (`useForm<ArticleDto>`)

**Validation rules match backend:**
- Title: 1-200 characters
- Content: 1-20,000 characters
- Tags: 0-100 characters, alphanumeric with commas/hyphens

---

### Question 8: How does the frontend handle pagination?

**Answer:**

ArticleList implements client-controlled pagination with server-side data fetching:

```typescript
const [page, setPage] = useState(0);
const [totalPages, setTotalPages] = useState(0);

useEffect(() => {
  fetchArticles();
}, [page, searchTitle]);

const fetchArticles = async () => {
  const response = await api.get('/articles', {
    params: { page, size: 5, title: searchTitle }
  });
  setArticles(response.data.content);
  setTotalPages(response.data.totalPages);
};
```

**Pagination controls:**
```tsx
<button onClick={() => setPage(p => p - 1)} disabled={page === 0}>
  Previous
</button>
<span>Page {page + 1} of {totalPages}</span>
<button onClick={() => setPage(p => p + 1)} disabled={page >= totalPages - 1}>
  Next
</button>
```

**Key points:**

1. **Zero-indexed pages** - Backend uses Spring Data convention (page 0 is first)
2. **Size parameter** - Fixed at 5 items per page
3. **Search integration** - Title filter resets to page 0 when changed
4. **Spring Page response** - Includes `content`, `totalPages`, `totalElements`, `number`

---

### Question 9: What is the purpose of `withCredentials: true` in Axios configuration?

**Answer:**

```typescript
const api = axios.create({
  baseURL: '/api',
  withCredentials: true
});
```

**Purpose:** Enables cross-origin credential sharing, specifically cookies.

**Why it's needed:**

1. **Cookie-based auth** - JWT is stored in HttpOnly cookie set by auth-service
2. **Cross-origin requests** - Frontend (port 8080) calls backend (ports 8081/8082)
3. **Default behavior** - Browsers don't send cookies on cross-origin requests by default

**What it enables:**
- Cookies sent with every request to backend
- Cookies from backend responses are stored
- Required for both directions of cookie flow

**Backend requirements:**
- CORS must explicitly allow credentials: `allowCredentials(true)`
- `Access-Control-Allow-Origin` cannot be `*` when credentials are used
- Must specify exact origin: `http://localhost:8080`

**Note:** In production with Nginx proxy, requests become same-origin, but `withCredentials` is still needed for the cookie to be included.

---

### Question 10: How would you implement optimistic updates for the article delete operation?

**Answer:**

Currently, the delete operation waits for server confirmation before updating UI. Optimistic updates would improve perceived performance:

**Current implementation:**
```typescript
const handleDelete = async (id: number) => {
  await api.delete(`/articles/${id}`);  // Wait for server
  setArticles(articles.filter(a => a.id !== id));  // Then update UI
};
```

**Optimistic implementation:**
```typescript
const handleDelete = async (id: number) => {
  // 1. Store current state for rollback
  const previousArticles = articles;

  // 2. Immediately update UI (optimistic)
  setArticles(articles.filter(a => a.id !== id));

  try {
    // 3. Perform actual delete
    await api.delete(`/articles/${id}`);
  } catch (error) {
    // 4. Rollback on failure
    setArticles(previousArticles);
    toast.error('Delete failed. Please try again.');
  }
};
```

**Considerations:**
- **User feedback** - Show subtle loading indicator even with optimistic update
- **Race conditions** - Handle if user navigates away during request
- **Consistency** - Other users won't see deletion until their next fetch
- **Error UX** - Rollback must be visually clear to user

---

## Auth Service (Spring Boot)

### Question 11: Explain the JWT token generation and validation process.

**Answer:**

**Token Generation (`JwtUtil.generateToken()`):**

```java
public String generateToken(String username, String role) {
    return Jwts.builder()
        .setSubject(username)                           // User identifier (email)
        .claim("role", role)                            // Custom claim for authorization
        .setIssuedAt(new Date())                        // Token creation time
        .setExpiration(new Date(System.currentTimeMillis() + expiration))
        .signWith(getSigningKey(), SignatureAlgorithm.HS256)  // HMAC-SHA256
        .compact();
}

private Key getSigningKey() {
    byte[] keyBytes = Decoders.BASE64.decode(secret);   // Base64-decode secret
    return Keys.hmacShaKeyFor(keyBytes);                // Create signing key
}
```

**Token Validation (`JwtUtil.validateToken()`):**

```java
public boolean validateToken(String token) {
    try {
        Jwts.parserBuilder()
            .setSigningKey(getSigningKey())
            .build()
            .parseClaimsJws(token);     // Throws if invalid
        return true;
    } catch (JwtException e) {
        return false;                   // Expired, malformed, wrong signature
    }
}
```

**Security considerations:**

1. **Secret key** - Must be at least 256 bits for HS256 (32 bytes), stored as environment variable
2. **Expiration** - 24 hours default, configurable via `JWT_EXPIRATION`
3. **Stateless** - No server-side session storage required
4. **Shared secret** - Both services use same secret for interoperability

---

### Question 12: How does the rate limiting work for login attempts?

**Answer:**

`RateLimitFilter` implements a sliding window rate limiter to prevent brute force attacks:

**Algorithm:**

```java
public class RateLimitFilter extends OncePerRequestFilter {
    private final Map<String, List<Long>> requestCounts = new ConcurrentHashMap<>();

    @Override
    protected void doFilterInternal(request, response, chain) {
        if (!request.getRequestURI().equals("/auth/login")) {
            chain.doFilter(request, response);
            return;
        }

        String clientIp = getClientIp(request);
        long now = System.currentTimeMillis();
        long windowStart = now - (windowSeconds * 1000);

        // Get requests in current window
        List<Long> requests = requestCounts.computeIfAbsent(clientIp, k -> new ArrayList<>());

        // Remove expired entries (sliding window)
        requests.removeIf(timestamp -> timestamp < windowStart);

        if (requests.size() >= maxRequests) {
            response.setStatus(429);  // Too Many Requests
            response.getWriter().write("Rate limit exceeded");
            return;
        }

        requests.add(now);
        chain.doFilter(request, response);
    }
}
```

**Configuration:**
- `rate.limit.login=5` - Maximum 5 attempts
- `rate.limit.login.window=60` - Per 60-second window

**IP detection (handles proxies):**
```java
private String getClientIp(HttpServletRequest request) {
    String xForwardedFor = request.getHeader("X-Forwarded-For");
    return xForwardedFor != null ? xForwardedFor.split(",")[0] : request.getRemoteAddr();
}
```

**Limitations:**
- In-memory storage - resets on restart, doesn't work in clustered deployments
- Would need Redis-backed implementation for production scale

---

### Question 13: Describe the password validation and encoding strategy.

**Answer:**

**Password Validation (PasswordValidator):**

The service enforces password strength requirements before encoding:

```java
public void validatePassword(String password) {
    if (password == null || password.length() < 8) {
        throw new IllegalArgumentException("Password must be at least 8 characters");
    }
    if (password.length() > 72) {
        throw new IllegalArgumentException("Password must not exceed 72 characters");
    }
    // Additional rules: uppercase, lowercase, digit requirements
}
```

**Why 72 character limit?** BCrypt only processes first 72 bytes. Longer passwords are truncated silently, which could cause security issues.

**Password Encoding (BCrypt):**

```java
@Bean
public PasswordEncoder passwordEncoder() {
    return new BCryptPasswordEncoder();  // Default: 10 rounds
}

// In AuthService
String encodedPassword = passwordEncoder.encode(rawPassword);
user.setPassword(encodedPassword);
```

**BCrypt features:**
- **Adaptive** - Work factor can be increased as hardware improves
- **Salted** - Each hash includes random salt (stored in hash string)
- **Slow by design** - ~100ms per hash makes brute force impractical

**Hash format:** `$2a$10$N9qo8uLOickgx2ZMRZoMye.IjqQBrkWinVu3/sXX7UPO`
- `$2a$` - BCrypt version
- `10` - Cost factor (2^10 iterations)
- Next 22 chars - Salt
- Remaining - Hash

---

### Question 14: How does the AdminInitializer ensure a default admin exists?

**Answer:**

`AdminInitializer` implements `ApplicationRunner` to execute on startup:

```java
@Component
public class AdminInitializer implements ApplicationRunner {

    @Value("${admin.email:admin@example.com}")
    private String adminEmail;

    @Value("${admin.password:password123}")
    private String adminPassword;

    @Override
    public void run(ApplicationArguments args) {
        if (userRepository.findByEmail(adminEmail).isEmpty()) {
            User admin = new User();
            admin.setEmail(adminEmail);
            admin.setPassword(passwordEncoder.encode(adminPassword));
            admin.setRole(Role.ADMIN);
            userRepository.save(admin);
            log.info("Admin user created: {}", adminEmail);
        }
    }
}
```

**Key points:**

1. **Idempotent** - Checks if admin exists before creating
2. **Configurable** - Email/password from environment variables
3. **Secure defaults warning** - Default credentials should be changed in production
4. **Order** - Runs after database connection is established

**Production considerations:**
- Set `ADMIN_EMAIL` and `ADMIN_PASSWORD` environment variables
- Consider using secrets management (Vault, K8s secrets)
- Log admin creation for audit trail

---

### Question 15: Explain the SecurityConfig and which endpoints are public vs. protected.

**Answer:**

```java
@Configuration
@EnableWebSecurity
public class SecurityConfig {

    @Bean
    public SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception {
        return http
            .csrf(csrf -> csrf.disable())           // Disabled: using JWT
            .sessionManagement(session ->
                session.sessionCreationPolicy(SessionCreationPolicy.STATELESS))
            .authorizeHttpRequests(auth -> auth
                .requestMatchers("/auth/login", "/auth/register").permitAll()
                .requestMatchers("/auth/validate").permitAll()
                .requestMatchers("/actuator/**").permitAll()
                .anyRequest().authenticated()
            )
            .build();
    }
}
```

**Public endpoints (no auth required):**
| Endpoint | Purpose |
|----------|---------|
| `POST /auth/login` | User authentication |
| `POST /auth/register` | User registration |
| `POST /auth/validate` | Token validation (used by blog-service) |
| `/actuator/**` | Health checks for Docker/K8s |

**Protected endpoints:**
- All other endpoints require valid JWT

**Why CSRF is disabled:**
- JWT-based authentication is inherently CSRF-resistant
- Tokens aren't auto-attached like cookies (although we use cookies, the validation happens via JWT parsing)
- Stateless design means no server session to protect

**Why stateless sessions:**
- No server-side session storage
- Enables horizontal scaling without session affinity
- JWT contains all necessary authentication info

---

### Question 16: How does the authentication flow work end-to-end?

**Answer:**

**Login Flow:**

```
1. User → Frontend: Enters email/password
2. Frontend → Auth Service: POST /api/auth/login {email, password}
3. Auth Service → Database: Load user by email
4. Auth Service: Verify password with BCrypt
5. Auth Service: Generate JWT with email + role claims
6. Auth Service → Frontend: Set-Cookie: token=<JWT>; HttpOnly; Path=/
7. Frontend: AuthContext.login() - sets isAuthenticated=true
8. Frontend → User: Redirect to /articles
```

**Subsequent request flow:**

```
1. User → Frontend: Navigate to /articles
2. Frontend → Nginx: GET /api/articles (cookie auto-attached)
3. Nginx → Blog Service: GET /articles + Cookie header
4. Blog Service JwtAuthFilter: Extract JWT from cookie
5. Blog Service JwtUtil: Validate signature + expiration
6. Blog Service: Extract username, load User from DB
7. Blog Service: Set SecurityContext with user + authorities
8. Blog Service → ArticleController: Handle request
9. Blog Service → Frontend: Return articles JSON
10. Frontend → User: Render article list
```

**Key components involved:**
- `AuthController` - Handles login/register/logout
- `AuthService` - Business logic for authentication
- `JwtUtil` - Token creation and parsing
- `JwtAuthFilter` - Intercepts requests, validates tokens
- `AuthContext` - Frontend state management

---

### Question 17: What happens if a user tries to register with an existing email?

**Answer:**

The registration flow includes duplicate email checking:

```java
// AuthService.register()
public AuthResponse register(RegisterRequest request) {
    // Check for existing user
    if (userRepository.findByEmail(request.getEmail()).isPresent()) {
        throw new EmailAlreadyExistsException("Email already registered");
    }

    // Validate password strength
    passwordValidator.validate(request.getPassword());

    // Create user
    User user = new User();
    user.setEmail(request.getEmail());
    user.setPassword(passwordEncoder.encode(request.getPassword()));
    user.setRole(Role.USER);
    userRepository.save(user);

    // Generate token and return
    String token = jwtUtil.generateToken(user.getEmail(), user.getRole().name());
    return new AuthResponse(token, user.getEmail());
}
```

**Error handling:**

```java
@RestControllerAdvice
public class GlobalExceptionHandler {

    @ExceptionHandler(EmailAlreadyExistsException.class)
    public ResponseEntity<ErrorResponse> handleEmailExists(EmailAlreadyExistsException e) {
        return ResponseEntity
            .status(HttpStatus.CONFLICT)  // 409
            .body(new ErrorResponse("Email already registered"));
    }
}
```

**Frontend handling:**
```typescript
try {
  await api.post('/auth/register', formData);
} catch (error) {
  if (error.response?.status === 409) {
    setError('email', { message: 'This email is already registered' });
  }
}
```

**Database constraint:** The `email` column also has a `UNIQUE` constraint as a safety net.

---

### Question 18: How would you implement refresh tokens in this architecture?

**Answer:**

Currently, the system uses single JWT tokens with 24-hour expiration. Refresh tokens would improve security:

**Proposed implementation:**

1. **Token pair on login:**
```java
public AuthResponse login(LoginRequest request) {
    // ... validate credentials

    String accessToken = jwtUtil.generateToken(user, Duration.ofMinutes(15));
    String refreshToken = jwtUtil.generateRefreshToken(user, Duration.ofDays(7));

    // Store refresh token hash in database
    user.setRefreshTokenHash(hashToken(refreshToken));
    userRepository.save(user);

    return new AuthResponse(accessToken, refreshToken);
}
```

2. **Refresh endpoint:**
```java
@PostMapping("/auth/refresh")
public AuthResponse refresh(@CookieValue("refresh_token") String refreshToken) {
    String email = jwtUtil.extractUsername(refreshToken);
    User user = userRepository.findByEmail(email).orElseThrow();

    // Validate refresh token hash matches stored value
    if (!hashToken(refreshToken).equals(user.getRefreshTokenHash())) {
        throw new InvalidTokenException("Refresh token revoked");
    }

    String newAccessToken = jwtUtil.generateToken(user, Duration.ofMinutes(15));
    return new AuthResponse(newAccessToken);
}
```

3. **Frontend auto-refresh:**
```typescript
api.interceptors.response.use(
  response => response,
  async error => {
    if (error.response?.status === 401 && !error.config._retry) {
      error.config._retry = true;
      await api.post('/auth/refresh');
      return api(error.config);  // Retry original request
    }
    return Promise.reject(error);
  }
);
```

**Benefits:**
- Short-lived access tokens limit exposure window
- Refresh tokens can be revoked server-side
- Reduces database lookups (access token validation is stateless)

---

### Question 19: What role does the UserDetailsService play in Spring Security?

**Answer:**

`UserDetailsService` is Spring Security's interface for loading user-specific data:

```java
@Bean
public UserDetailsService userDetailsService(UserRepository userRepository) {
    return email -> userRepository.findByEmail(email)
        .orElseThrow(() -> new UsernameNotFoundException("User not found: " + email));
}
```

**How it's used:**

1. **Authentication process:**
   - `AuthenticationManager.authenticate()` is called with credentials
   - `DaoAuthenticationProvider` uses `UserDetailsService` to load user
   - Provider compares submitted password with stored hash

2. **User entity implements UserDetails:**
```java
@Entity
public class User implements UserDetails {
    @Override
    public Collection<? extends GrantedAuthority> getAuthorities() {
        return List.of(new SimpleGrantedAuthority("ROLE_" + role.name()));
    }

    @Override
    public String getUsername() {
        return email;  // Using email as username
    }

    @Override
    public String getPassword() {
        return password;
    }

    // isAccountNonExpired(), isAccountNonLocked(), etc. return true
}
```

**Why this pattern:**
- Decouples Spring Security from specific user storage
- Same interface works with JDBC, LDAP, custom databases
- User entity carries both business data and security information

---

### Question 20: How do you handle token expiration gracefully?

**Answer:**

**Backend detection:**

```java
// JwtUtil.validateToken()
public boolean validateToken(String token) {
    try {
        Jwts.parserBuilder()
            .setSigningKey(getSigningKey())
            .build()
            .parseClaimsJws(token);
        return true;
    } catch (ExpiredJwtException e) {
        log.debug("Token expired at: {}", e.getClaims().getExpiration());
        return false;
    } catch (JwtException e) {
        log.debug("Invalid token: {}", e.getMessage());
        return false;
    }
}
```

**Filter response:**

```java
// JwtAuthFilter
if (!jwtUtil.validateToken(token)) {
    response.setStatus(HttpServletResponse.SC_UNAUTHORIZED);
    response.getWriter().write("{\"error\": \"Token expired\"}");
    return;
}
```

**Frontend handling:**

```typescript
// api.ts interceptor
api.interceptors.response.use(
  response => response,
  error => {
    if (error.response?.status === 401) {
      // Clear local auth state
      window.dispatchEvent(new CustomEvent('auth:logout'));

      // Optionally show user-friendly message
      toast.info('Your session has expired. Please log in again.');
    }
    return Promise.reject(error);
  }
);
```

**UX considerations:**
- Show warning before expiration (check `exp` claim client-side)
- Implement token refresh to avoid interrupting user flow
- Preserve user's current work if possible (save draft, etc.)

---

## Blog Service (Spring Boot)

### Question 21: Explain the @PreAuthorize annotations and how method-level security works.

**Answer:**

Method-level security uses SpEL (Spring Expression Language) to control access:

**Configuration:**
```java
@Configuration
@EnableMethodSecurity  // Enables @PreAuthorize, @PostAuthorize
public class SecurityConfig { }
```

**Usage in ArticleService:**

```java
@PreAuthorize("hasRole('ADMIN') or @articleSecurity.isOwner(authentication, #id)")
public ArticleDto getArticle(Long id) {
    return articleRepository.findById(id)
        .map(this::toDto)
        .orElseThrow(() -> new ArticleNotFoundException(id));
}

@PreAuthorize("hasRole('ADMIN') or @articleSecurity.isOwner(authentication, #id)")
public void deleteArticle(Long id) {
    articleRepository.deleteById(id);
}
```

**SpEL breakdown:**
- `hasRole('ADMIN')` - Checks if user has ROLE_ADMIN authority
- `@articleSecurity` - References Spring bean by name
- `.isOwner(authentication, #id)` - Calls method with auth object and method parameter
- `#id` - Binds to method parameter named `id`

**ArticleSecurity bean:**
```java
@Component("articleSecurity")
public class ArticleSecurity {
    public boolean isOwner(Authentication auth, Long articleId) {
        User user = (User) auth.getPrincipal();
        Article article = articleRepository.findById(articleId).orElse(null);
        return article != null && article.getAuthor().getId().equals(user.getId());
    }
}
```

**How it works internally:**
1. Spring AOP creates proxy around secured methods
2. Before method execution, `PreAuthorizeAuthorizationManager` evaluates expression
3. If expression returns false, `AccessDeniedException` is thrown
4. Global exception handler converts to 403 Forbidden response

---

### Question 22: How does the Redis caching work for articles?

**Answer:**

**Configuration:**
```java
@Configuration
@EnableCaching
public class RedisConfig {

    @Bean
    public RedisCacheConfiguration cacheConfiguration() {
        return RedisCacheConfiguration.defaultCacheConfig()
            .entryTtl(Duration.ofHours(1))
            .serializeValuesWith(
                RedisSerializationContext.SerializationPair.fromSerializer(
                    new GenericJackson2JsonRedisSerializer()
                )
            );
    }
}
```

**Cache annotations in ArticleService:**

```java
// Cache on read
@Cacheable(value = "articles", key = "#id")
public ArticleDto getArticle(Long id) {
    return articleRepository.findById(id).map(this::toDto).orElseThrow();
}

// Evict on update
@CacheEvict(value = "articles", key = "#id")
public ArticleDto updateArticle(Long id, ArticleDto dto) {
    // Update logic
}

// Evict on delete
@CacheEvict(value = "articles", key = "#id")
public void deleteArticle(Long id) {
    articleRepository.deleteById(id);
}
```

**Cache flow:**

1. **Cache hit:** Request → Check Redis → Found → Return cached value (skip DB)
2. **Cache miss:** Request → Check Redis → Not found → Query DB → Store in Redis → Return

**Redis key format:** `articles::42` (cache name + key)

**Graceful degradation:**
```java
@Bean
public CacheErrorHandler errorHandler() {
    return new CacheErrorHandler() {
        @Override
        public void handleCacheGetError(RuntimeException e, Cache cache, Object key) {
            log.warn("Cache get failed: {}", e.getMessage());
            // Continue without cache - query database instead
        }
    };
}
```

---

### Question 23: What is the N+1 query problem and how is it solved here?

**Answer:**

**The N+1 problem:**
When fetching a list of entities with relationships, lazy loading causes:
- 1 query for the list of articles
- N additional queries for each article's author

```sql
-- Without optimization: N+1 queries
SELECT * FROM articles;                    -- 1 query
SELECT * FROM users WHERE id = 1;          -- N queries
SELECT * FROM users WHERE id = 2;
SELECT * FROM users WHERE id = 3;
...
```

**Solution with @EntityGraph:**

```java
public interface ArticleRepository extends JpaRepository<Article, Long> {

    @EntityGraph(attributePaths = {"author"})
    List<Article> findAll();

    @EntityGraph(attributePaths = {"author"})
    Page<Article> findByTitleContainingIgnoreCase(String title, Pageable pageable);

    @Query("SELECT a FROM Article a JOIN FETCH a.author WHERE a.id = :id")
    Optional<Article> findByIdWithAuthor(@Param("id") Long id);
}
```

**Resulting SQL:**
```sql
-- With EntityGraph: 1 query with JOIN
SELECT a.*, u.* FROM articles a
LEFT JOIN users u ON a.author_id = u.id;
```

**Alternative: JOIN FETCH in JPQL:**
```java
@Query("SELECT a FROM Article a JOIN FETCH a.author")
List<Article> findAllWithAuthors();
```

**When to use each:**
- `@EntityGraph` - Declarative, cleaner for simple cases
- `JOIN FETCH` - More control, supports complex queries
- Both: Avoid lazy loading N+1 problem

---

### Question 24: Explain the @Retryable annotation and why it's used.

**Answer:**

`@Retryable` from Spring Retry handles transient failures automatically:

```java
@Retryable(
    value = {SQLException.class, DataAccessException.class},
    maxAttempts = 3,
    backoff = @Backoff(delay = 1000, multiplier = 2)
)
public Page<ArticleDto> getAllArticles(Pageable pageable, String title) {
    return articleRepository.findByTitleContaining(title, pageable)
        .map(this::toDto);
}
```

**Configuration breakdown:**
- `value` - Exception types that trigger retry
- `maxAttempts = 3` - Try up to 3 times total
- `delay = 1000` - Wait 1 second before first retry
- `multiplier = 2` - Exponential backoff (1s, 2s, 4s)

**When retries help:**
- Database connection pool exhausted temporarily
- Network hiccup between service and database
- Deadlock detected and transaction rolled back

**When retries don't help:**
- Constraint violation (duplicate key)
- Authentication failure
- Business logic errors

**Required dependency:**
```xml
<dependency>
    <groupId>org.springframework.retry</groupId>
    <artifactId>spring-retry</artifactId>
</dependency>
```

**Enable with:**
```java
@EnableRetry
@SpringBootApplication
public class BlogServiceApplication { }
```

---

### Question 25: How does the JwtAuthFilter work in the blog service?

**Answer:**

`JwtAuthFilter` intercepts every request to validate JWT and set up security context:

```java
@Component
public class JwtAuthFilter extends OncePerRequestFilter {

    @Override
    protected void doFilterInternal(request, response, filterChain) {
        // 1. Extract token from header or cookie
        String token = extractToken(request);

        if (token != null && jwtUtil.validateToken(token)) {
            // 2. Extract username from token
            String username = jwtUtil.extractUsername(token);

            // 3. Load full user from database
            User user = userRepository.findByEmail(username).orElse(null);

            if (user != null) {
                // 4. Create authentication object
                UsernamePasswordAuthenticationToken auth =
                    new UsernamePasswordAuthenticationToken(
                        user,                    // Principal
                        null,                    // Credentials (not needed)
                        user.getAuthorities()    // Granted authorities (ROLE_USER/ADMIN)
                    );

                // 5. Set in security context
                SecurityContextHolder.getContext().setAuthentication(auth);
            }
        }

        // 6. Continue filter chain
        filterChain.doFilter(request, response);
    }

    private String extractToken(HttpServletRequest request) {
        // Try Authorization header first
        String authHeader = request.getHeader("Authorization");
        if (authHeader != null && authHeader.startsWith("Bearer ")) {
            return authHeader.substring(7);
        }

        // Fall back to cookie
        Cookie[] cookies = request.getCookies();
        if (cookies != null) {
            for (Cookie cookie : cookies) {
                if ("token".equals(cookie.getName())) {
                    return cookie.getValue();
                }
            }
        }
        return null;
    }
}
```

**Filter chain position:**
```java
http.addFilterBefore(jwtAuthFilter, UsernamePasswordAuthenticationFilter.class);
```

**Why load user from database?**
- Token only contains email and role
- Need full User object for ownership checks
- Ensures user still exists (not deleted after token issued)

---

### Question 26: How is article ownership enforced for updates and deletes?

**Answer:**

Ownership is enforced at multiple levels:

**1. Controller level (basic validation):**
```java
@PutMapping("/{id}")
public ResponseEntity<ArticleDto> updateArticle(
    @PathVariable Long id,
    @Valid @RequestBody ArticleDto articleDto
) {
    return ResponseEntity.ok(articleService.updateArticle(id, articleDto));
}
```

**2. Service level (@PreAuthorize):**
```java
@PreAuthorize("hasRole('ADMIN') or @articleSecurity.isOwner(authentication, #id)")
public ArticleDto updateArticle(Long id, ArticleDto dto) {
    Article article = articleRepository.findById(id)
        .orElseThrow(() -> new ArticleNotFoundException(id));
    // Update fields
    return toDto(articleRepository.save(article));
}
```

**3. ArticleSecurity bean:**
```java
@Component("articleSecurity")
public class ArticleSecurity {

    public boolean isOwner(Authentication authentication, Long articleId) {
        if (authentication == null) return false;

        User user = (User) authentication.getPrincipal();

        // Admin bypass
        if (user.getRole() == Role.ADMIN) return true;

        // Check ownership
        return articleRepository.findById(articleId)
            .map(article -> article.getAuthor().getId().equals(user.getId()))
            .orElse(false);
    }
}
```

**Access control matrix:**
| Action | Owner | Admin | Other User |
|--------|-------|-------|------------|
| View own article | ✓ | ✓ | ✗ |
| Edit own article | ✓ | ✓ | ✗ |
| Delete own article | ✓ | ✓ | ✗ |
| View any article | ✗ | ✓ | ✗ |
| Edit any article | ✗ | ✓ | ✗ |

---

### Question 27: Explain the ArticleDto and validation annotations.

**Answer:**

DTOs (Data Transfer Objects) separate API contract from internal entity structure:

```java
public class ArticleDto {

    private Long id;

    @NotBlank(message = "Title is required")
    @Size(min = 1, max = 200, message = "Title must be between 1 and 200 characters")
    private String title;

    @NotBlank(message = "Content is required")
    @Size(min = 1, max = 20000, message = "Content must be between 1 and 20000 characters")
    private String content;

    @Size(max = 100, message = "Tags must not exceed 100 characters")
    @Pattern(regexp = "^[a-zA-Z0-9,\\s-]*$", message = "Tags can only contain letters, numbers, commas, spaces, and hyphens")
    private String tags;

    @NotBlank(message = "Publish status is required")
    @Pattern(regexp = "^(draft|published)$", message = "Status must be 'draft' or 'published'")
    private String publishStatus;

    // Read-only fields (set by server)
    private Long authorId;
    private String authorEmail;
    private LocalDateTime createdAt;
    private LocalDateTime updatedAt;
}
```

**Validation annotations:**

| Annotation | Purpose |
|------------|---------|
| `@NotBlank` | Not null, not empty, not whitespace-only |
| `@Size` | String length constraints |
| `@Pattern` | Regex validation |
| `@Valid` | Triggers validation on nested objects |

**Controller usage:**
```java
@PostMapping
public ResponseEntity<ArticleDto> createArticle(@Valid @RequestBody ArticleDto dto) {
    // If validation fails, MethodArgumentNotValidException thrown
    return ResponseEntity.status(HttpStatus.CREATED).body(articleService.create(dto));
}
```

**Global exception handling:**
```java
@ExceptionHandler(MethodArgumentNotValidException.class)
public ResponseEntity<Map<String, String>> handleValidationErrors(MethodArgumentNotValidException ex) {
    Map<String, String> errors = ex.getBindingResult().getFieldErrors().stream()
        .collect(Collectors.toMap(
            FieldError::getField,
            FieldError::getDefaultMessage
        ));
    return ResponseEntity.badRequest().body(errors);
}
```

---

### Question 28: How does pagination work in the ArticleController?

**Answer:**

Spring Data provides built-in pagination support:

**Controller:**
```java
@GetMapping
public ResponseEntity<Page<ArticleSummaryDto>> getAllArticles(
    @RequestParam(defaultValue = "0") @Min(0) int page,
    @RequestParam(defaultValue = "10") @Min(1) @Max(100) int size,
    @RequestParam(required = false) String title
) {
    Pageable pageable = PageRequest.of(page, size, Sort.by("createdAt").descending());
    return ResponseEntity.ok(articleService.getAllArticles(pageable, title));
}
```

**Service:**
```java
public Page<ArticleSummaryDto> getAllArticles(Pageable pageable, String title) {
    Page<Article> articles;

    if (isAdmin()) {
        articles = title != null
            ? articleRepository.findByTitleContainingIgnoreCase(title, pageable)
            : articleRepository.findAll(pageable);
    } else {
        User currentUser = getCurrentUser();
        articles = title != null
            ? articleRepository.findByAuthorAndTitleContainingIgnoreCase(currentUser, title, pageable)
            : articleRepository.findByAuthor(currentUser, pageable);
    }

    return articles.map(this::toSummaryDto);
}
```

**Repository:**
```java
@EntityGraph(attributePaths = {"author"})
Page<Article> findByAuthor(User author, Pageable pageable);
```

**Response structure (Spring's Page wrapper):**
```json
{
  "content": [/* articles */],
  "pageable": {
    "pageNumber": 0,
    "pageSize": 10,
    "sort": { "sorted": true, "orders": [{"property": "createdAt", "direction": "DESC"}] }
  },
  "totalElements": 42,
  "totalPages": 5,
  "last": false,
  "first": true,
  "numberOfElements": 10
}
```

---

### Question 29: What happens when Redis is unavailable?

**Answer:**

The application is designed to gracefully degrade when Redis is down:

**CacheErrorHandler configuration:**
```java
@Bean
public CacheErrorHandler errorHandler() {
    return new CacheErrorHandler() {
        @Override
        public void handleCacheGetError(RuntimeException e, Cache cache, Object key) {
            log.warn("Cache GET failed for key {}: {}", key, e.getMessage());
            // Don't throw - method will execute and return DB result
        }

        @Override
        public void handleCachePutError(RuntimeException e, Cache cache, Object key, Object value) {
            log.warn("Cache PUT failed for key {}: {}", key, e.getMessage());
            // Don't throw - operation succeeded, just not cached
        }

        @Override
        public void handleCacheEvictError(RuntimeException e, Cache cache, Object key) {
            log.warn("Cache EVICT failed for key {}: {}", key, e.getMessage());
        }

        @Override
        public void handleCacheClearError(RuntimeException e, Cache cache) {
            log.warn("Cache CLEAR failed: {}", e.getMessage());
        }
    };
}
```

**Behavior when Redis is down:**

| Operation | With Redis | Without Redis |
|-----------|------------|---------------|
| Read article | Check cache → DB if miss | Direct DB query |
| Update article | Evict cache → Update DB | Update DB (stale cache possible) |
| Delete article | Evict cache → Delete DB | Delete DB (orphan cache entry) |

**Implications:**
- **Performance** - Every request hits database
- **Consistency** - Stale data possible if Redis comes back with old entries
- **Monitoring** - Log warnings help identify Redis issues

**Best practice:** Set Redis TTL so old entries expire naturally:
```properties
spring.cache.redis.time-to-live=3600000  # 1 hour
```

---

### Question 30: How would you implement full-text search for articles?

**Answer:**

Currently, the app uses simple `LIKE` queries. For full-text search:

**Option 1: PostgreSQL Full-Text Search**

```java
// Repository
@Query(value = """
    SELECT a.* FROM articles a
    WHERE to_tsvector('english', a.title || ' ' || a.content)
          @@ plainto_tsquery('english', :query)
    ORDER BY ts_rank(to_tsvector('english', a.title || ' ' || a.content),
                     plainto_tsquery('english', :query)) DESC
    """, nativeQuery = true)
Page<Article> fullTextSearch(@Param("query") String query, Pageable pageable);
```

**Add index for performance:**
```sql
CREATE INDEX idx_articles_fts ON articles
USING gin(to_tsvector('english', title || ' ' || content));
```

**Option 2: Elasticsearch Integration**

```java
// Elasticsearch entity
@Document(indexName = "articles")
public class ArticleDocument {
    @Id
    private Long id;

    @Field(type = FieldType.Text, analyzer = "english")
    private String title;

    @Field(type = FieldType.Text, analyzer = "english")
    private String content;
}

// Repository
public interface ArticleSearchRepository extends ElasticsearchRepository<ArticleDocument, Long> {
    Page<ArticleDocument> findByTitleOrContent(String title, String content, Pageable pageable);
}

// Sync on article changes
@EventListener
public void onArticleSaved(ArticleSavedEvent event) {
    articleSearchRepository.save(toDocument(event.getArticle()));
}
```

**Comparison:**

| Feature | PostgreSQL FTS | Elasticsearch |
|---------|---------------|---------------|
| Setup complexity | Low | High |
| Relevance scoring | Basic | Advanced |
| Scaling | Single node | Distributed |
| Additional infra | None | ES cluster |
| Best for | Small-medium apps | Large-scale search |

---

## Database (PostgreSQL/JPA)

### Question 31: Explain the entity relationships and database schema.

**Answer:**

**Entity-Relationship Diagram:**

```
┌─────────────────────┐       ┌─────────────────────────┐
│       users         │       │        articles         │
├─────────────────────┤       ├─────────────────────────┤
│ id (PK)             │───────│ id (PK)                 │
│ email (UNIQUE)      │   1:N │ title                   │
│ password            │       │ content                 │
│ role                │       │ tags                    │
│ created_at          │       │ publish_status          │
│ updated_at          │       │ author_id (FK) ─────────│
└─────────────────────┘       │ created_at              │
                              │ updated_at              │
                              └─────────────────────────┘
```

**JPA Entities:**

```java
@Entity
@Table(name = "users")
public class User implements UserDetails {
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;

    @Column(unique = true, nullable = false)
    private String email;

    @Column(nullable = false)
    private String password;

    @Enumerated(EnumType.STRING)
    private Role role;

    @CreationTimestamp
    private LocalDateTime createdAt;

    @UpdateTimestamp
    private LocalDateTime updatedAt;
}

@Entity
@Table(name = "articles")
public class Article {
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;

    @Column(nullable = false, length = 200)
    private String title;

    @Column(nullable = false, columnDefinition = "TEXT")
    private String content;

    @Column(length = 100)
    private String tags;

    @Enumerated(EnumType.STRING)
    private PublishStatus publishStatus;

    @ManyToOne(fetch = FetchType.LAZY)
    @JoinColumn(name = "author_id", nullable = false)
    private User author;

    @CreationTimestamp
    private LocalDateTime createdAt;

    @UpdateTimestamp
    private LocalDateTime updatedAt;
}
```

**Relationship:** One User can have many Articles (1:N)

---

### Question 32: What is the difference between FetchType.LAZY and EAGER?

**Answer:**

**FetchType.EAGER:**
- Related entity loaded immediately with parent
- Always executes JOIN or additional query
- More memory usage, potential over-fetching

```java
@ManyToOne(fetch = FetchType.EAGER)  // Default for @ManyToOne
private User author;

// Loading article automatically loads author
Article article = articleRepository.findById(1L);
// SQL: SELECT a.*, u.* FROM articles a JOIN users u ON a.author_id = u.id WHERE a.id = 1
```

**FetchType.LAZY:**
- Related entity loaded only when accessed
- Requires active Hibernate session
- More efficient but risks LazyInitializationException

```java
@ManyToOne(fetch = FetchType.LAZY)
private User author;

// Loading article does NOT load author
Article article = articleRepository.findById(1L);
// SQL: SELECT * FROM articles WHERE id = 1

// Accessing author triggers second query
String email = article.getAuthor().getEmail();
// SQL: SELECT * FROM users WHERE id = ?
```

**Best practices:**

1. **Default to LAZY** - Avoid loading data you don't need
2. **Use @EntityGraph or JOIN FETCH** - When you know you need related data
3. **DTO projections** - Select only needed fields for read operations

```java
// Explicitly fetch when needed
@EntityGraph(attributePaths = {"author"})
Optional<Article> findByIdWithAuthor(Long id);
```

---

### Question 33: What is the purpose of `ddl-auto=update` and its risks?

**Answer:**

**`spring.jpa.hibernate.ddl-auto` options:**

| Value | Description |
|-------|-------------|
| `none` | No schema management |
| `validate` | Validate schema matches entities, fail if mismatch |
| `update` | Update schema to match entities (add columns/tables) |
| `create` | Drop and recreate schema on startup |
| `create-drop` | Create on startup, drop on shutdown |

**Current setting:** `update`

```properties
spring.jpa.hibernate.ddl-auto=${DDL_AUTO:update}
```

**What `update` does:**
- Adds new tables for new entities
- Adds new columns for new fields
- Creates indexes and constraints
- **Does NOT:** Drop columns, change column types, drop tables

**Risks in production:**

1. **Data loss potential** - Accidental entity deletion could cause issues
2. **Schema drift** - Multiple services could create conflicting schemas
3. **No rollback** - Changes are immediate and irreversible
4. **Performance** - Schema inspection on every startup

**Production recommendation:**

```properties
# Production
spring.jpa.hibernate.ddl-auto=validate
```

**Use migration tools:**
- **Flyway** or **Liquibase** for versioned migrations
- Track schema changes in version control
- Support rollback and repeatable migrations

```java
// Flyway migration example: V1__create_articles_table.sql
CREATE TABLE articles (
    id BIGSERIAL PRIMARY KEY,
    title VARCHAR(200) NOT NULL,
    content TEXT NOT NULL,
    author_id BIGINT REFERENCES users(id)
);
```

---

### Question 34: How do @CreationTimestamp and @UpdateTimestamp work?

**Answer:**

These Hibernate annotations automatically manage timestamp fields:

```java
@Entity
public class Article {

    @CreationTimestamp
    @Column(updatable = false)
    private LocalDateTime createdAt;

    @UpdateTimestamp
    private LocalDateTime updatedAt;
}
```

**@CreationTimestamp:**
- Set to current time when entity is first persisted
- `updatable = false` prevents changes on update
- Only set on INSERT, never on UPDATE

**@UpdateTimestamp:**
- Set to current time on INSERT and every UPDATE
- Automatically updated by Hibernate pre-update listener

**How it works internally:**

```java
// Hibernate's EventListener
@PrePersist
public void onCreate() {
    createdAt = LocalDateTime.now();
    updatedAt = LocalDateTime.now();
}

@PreUpdate
public void onUpdate() {
    updatedAt = LocalDateTime.now();
}
```

**Database-level alternative:**

```sql
CREATE TABLE articles (
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Trigger for update
CREATE TRIGGER update_timestamp
BEFORE UPDATE ON articles
FOR EACH ROW EXECUTE FUNCTION update_modified_column();
```

**Advantages of Hibernate approach:**
- Timezone handling consistent with JVM
- Works across different databases
- Testable (can mock time in tests)

---

### Question 35: Explain transaction management in this application.

**Answer:**

**Default behavior:**

Spring Data JPA repositories are transactional by default:
- Read operations: Read-only transaction
- Write operations: Read-write transaction

**Service-level transactions:**

```java
@Service
@Transactional  // All public methods are transactional
public class ArticleService {

    @Transactional(readOnly = true)  // Optimization for reads
    public ArticleDto getArticle(Long id) {
        return toDto(articleRepository.findById(id).orElseThrow());
    }

    @Transactional  // Read-write (default)
    public ArticleDto createArticle(ArticleDto dto) {
        Article article = toEntity(dto);
        return toDto(articleRepository.save(article));
    }

    @Transactional(rollbackFor = Exception.class)
    public void complexOperation() {
        // If any exception occurs, entire transaction rolls back
        articleRepository.save(article1);
        articleRepository.save(article2);
        externalService.notify();  // If this fails, saves are rolled back
    }
}
```

**Transaction propagation:**

```java
@Transactional(propagation = Propagation.REQUIRED)  // Default
public void methodA() {
    // Uses existing transaction or creates new one
}

@Transactional(propagation = Propagation.REQUIRES_NEW)
public void methodB() {
    // Always creates new transaction, suspends existing
}
```

**Isolation levels:**

```java
@Transactional(isolation = Isolation.READ_COMMITTED)  // Default for PostgreSQL
public void readData() {
    // Prevents dirty reads
}
```

**Common pitfall - self-invocation:**

```java
@Service
public class ArticleService {
    public void publicMethod() {
        this.transactionalMethod();  // Transaction NOT applied!
    }

    @Transactional
    public void transactionalMethod() { }
}
```

Spring AOP proxies don't intercept self-calls. Solution: Inject self or use `TransactionTemplate`.

---

### Question 36: How would you implement soft deletes?

**Answer:**

Soft deletes mark records as deleted without removing them, enabling data recovery and audit trails:

**Entity modification:**

```java
@Entity
@Table(name = "articles")
@SQLDelete(sql = "UPDATE articles SET deleted = true, deleted_at = NOW() WHERE id = ?")
@Where(clause = "deleted = false")  // Hibernate filter
public class Article {

    @Column(nullable = false)
    private boolean deleted = false;

    private LocalDateTime deletedAt;

    private Long deletedBy;  // User who deleted
}
```

**How it works:**

1. `@SQLDelete` - Overrides DELETE SQL with UPDATE
2. `@Where` - Automatically adds `deleted = false` to all queries
3. Normal JPA operations work transparently

**Querying deleted records:**

```java
// Standard query - only active records
List<Article> active = articleRepository.findAll();

// Include deleted - use native query
@Query(value = "SELECT * FROM articles WHERE id = :id", nativeQuery = true)
Optional<Article> findByIdIncludingDeleted(@Param("id") Long id);

// Or use filters
@FilterDef(name = "deletedFilter", parameters = @ParamDef(name = "isDeleted", type = Boolean.class))
@Filter(name = "deletedFilter", condition = "deleted = :isDeleted")
public class Article { }

// Enable filter in service
entityManager.unwrap(Session.class)
    .enableFilter("deletedFilter")
    .setParameter("isDeleted", true);
```

**Recovery:**

```java
@Transactional
public void restoreArticle(Long id) {
    Article article = findByIdIncludingDeleted(id)
        .orElseThrow(() -> new ArticleNotFoundException(id));
    article.setDeleted(false);
    article.setDeletedAt(null);
    articleRepository.save(article);
}
```

---

### Question 37: What indexes would you add and why?

**Answer:**

**Current init.sql indexes:**

```sql
CREATE INDEX IF NOT EXISTS idx_users_email ON users(email);
CREATE INDEX IF NOT EXISTS idx_articles_author ON articles(author_id);
CREATE INDEX IF NOT EXISTS idx_articles_title ON articles(title);
```

**Additional recommended indexes:**

```sql
-- 1. Composite index for user's articles with search
CREATE INDEX idx_articles_author_title
ON articles(author_id, title varchar_pattern_ops);
-- Optimizes: WHERE author_id = ? AND title LIKE 'search%'

-- 2. Covering index for article list
CREATE INDEX idx_articles_list
ON articles(author_id, created_at DESC)
INCLUDE (id, title, publish_status);
-- Avoids table lookup for listing queries

-- 3. Partial index for published articles
CREATE INDEX idx_articles_published
ON articles(created_at DESC)
WHERE publish_status = 'PUBLISHED';
-- Optimizes public article feeds

-- 4. Full-text search index
CREATE INDEX idx_articles_fts
ON articles USING gin(to_tsvector('english', title || ' ' || content));
-- Enables efficient full-text search
```

**Index selection criteria:**

| Consider indexing when... | Example |
|---------------------------|---------|
| Column in WHERE clause | `author_id` for filtering |
| Column in JOIN condition | `author_id` as foreign key |
| Column in ORDER BY | `created_at` for sorting |
| Column in GROUP BY | Statistics queries |
| High selectivity | Unique or near-unique values |

**When NOT to index:**
- Small tables (< 1000 rows)
- Columns with few distinct values (e.g., boolean `deleted`)
- Columns rarely queried
- Heavy write tables (indexes slow writes)

**Monitoring in PostgreSQL:**
```sql
-- Find unused indexes
SELECT indexrelname, idx_scan FROM pg_stat_user_indexes WHERE idx_scan = 0;

-- Find missing indexes (sequential scans on large tables)
SELECT relname, seq_scan, seq_tup_read FROM pg_stat_user_tables
WHERE seq_tup_read > 100000;
```

---

## Blog Cache (Redis)

### Question 38: Explain the Redis configuration and eviction policy.

**Answer:**

**redis.conf settings:**

```conf
# Memory limit
maxmemory 512mb

# Eviction policy when memory is full
maxmemory-policy allkeys-lru

# Persistence
appendonly yes
appendfsync everysec

# Database count
databases 16
```

**Eviction policies explained:**

| Policy | Description |
|--------|-------------|
| `noeviction` | Return errors when memory full |
| `allkeys-lru` | Evict least recently used keys (current choice) |
| `allkeys-lfu` | Evict least frequently used keys |
| `volatile-lru` | LRU among keys with TTL only |
| `volatile-ttl` | Evict keys with shortest TTL |
| `allkeys-random` | Evict random keys |

**Why `allkeys-lru`:**
- All cached articles are evictable (no critical permanent data)
- LRU keeps frequently accessed articles in cache
- Natural fit for read-heavy content workloads

**Persistence options:**

1. **RDB (Snapshotting):**
   - Point-in-time snapshots
   - Configurable: save after N changes in M seconds
   - Good for disaster recovery

2. **AOF (Append-Only File):**
   - Logs every write operation
   - `appendfsync everysec` - fsync every second (trade-off: may lose 1s of data)
   - Better durability, larger files

**Current setup uses both:**
- AOF for durability (every second)
- RDB snapshots as backup (default intervals)

---

### Question 39: How would you implement distributed caching with multiple instances?

**Answer:**

Current architecture uses single Redis instance. For scaling:

**Option 1: Redis Cluster**

```yaml
# docker-compose.yml
services:
  redis-1:
    image: redis:7-alpine
    command: redis-server --cluster-enabled yes

  redis-2:
    image: redis:7-alpine
    command: redis-server --cluster-enabled yes

  redis-3:
    image: redis:7-alpine
    command: redis-server --cluster-enabled yes
```

**Spring Boot configuration:**
```yaml
spring:
  redis:
    cluster:
      nodes:
        - redis-1:6379
        - redis-2:6379
        - redis-3:6379
```

**Option 2: Redis Sentinel (HA without sharding)**

```yaml
spring:
  redis:
    sentinel:
      master: mymaster
      nodes:
        - sentinel-1:26379
        - sentinel-2:26379
        - sentinel-3:26379
```

**Key considerations:**

1. **Key distribution** - Redis Cluster uses hash slots (16384 slots)
2. **Multi-key operations** - Keys must be on same node (use hash tags: `{user:1}:articles`)
3. **Failover** - Sentinel/Cluster handle automatic failover
4. **Connection pooling** - Use Lettuce (default) with pooling for high throughput

**Application changes:**

```java
@Configuration
public class RedisConfig {

    @Bean
    public LettuceConnectionFactory connectionFactory(RedisClusterConfiguration clusterConfig) {
        LettuceClientConfiguration clientConfig = LettuceClientConfiguration.builder()
            .readFrom(ReadFrom.REPLICA_PREFERRED)  // Read from replicas
            .build();
        return new LettuceConnectionFactory(clusterConfig, clientConfig);
    }
}
```

---

### Question 40: What is cache stampede and how would you prevent it?

**Answer:**

**Cache stampede (thundering herd):**
When a popular cached item expires, many concurrent requests hit the database simultaneously to regenerate it.

```
Time: 0ms   Cache expires for article:popular
Time: 1ms   Request 1 checks cache → MISS → queries DB
Time: 2ms   Request 2 checks cache → MISS → queries DB
Time: 3ms   Request 3 checks cache → MISS → queries DB
...
Time: 10ms  100 requests all hitting DB simultaneously
```

**Prevention strategies:**

**1. Probabilistic early expiration:**

```java
public ArticleDto getArticle(Long id) {
    CacheEntry entry = cache.get("article:" + id);

    if (entry != null) {
        // Probabilistically refresh before actual expiry
        double probability = Math.random();
        double expiryRatio = (entry.getTtl() - entry.getRemainingTtl()) / entry.getTtl();

        if (probability < expiryRatio * 0.1) {  // 10% chance when close to expiry
            refreshCacheAsync(id);
        }
        return entry.getValue();
    }

    return refreshAndCache(id);
}
```

**2. Locking (single-flight):**

```java
private final Map<Long, Lock> locks = new ConcurrentHashMap<>();

public ArticleDto getArticle(Long id) {
    ArticleDto cached = cache.get("article:" + id);
    if (cached != null) return cached;

    Lock lock = locks.computeIfAbsent(id, k -> new ReentrantLock());

    if (lock.tryLock()) {
        try {
            // Double-check after acquiring lock
            cached = cache.get("article:" + id);
            if (cached != null) return cached;

            // Only one thread fetches from DB
            return refreshAndCache(id);
        } finally {
            lock.unlock();
            locks.remove(id);
        }
    } else {
        // Wait for other thread to populate cache
        Thread.sleep(50);
        return getArticle(id);  // Retry
    }
}
```

**3. Background refresh (never expire):**

```java
@Scheduled(fixedRate = 300000)  // Every 5 minutes
public void refreshPopularArticles() {
    List<Long> popularIds = analyticsService.getPopularArticleIds();
    for (Long id : popularIds) {
        Article article = articleRepository.findById(id).orElse(null);
        if (article != null) {
            cache.put("article:" + id, toDto(article));
        }
    }
}
```

---

### Question 41: How do you ensure cache consistency with the database?

**Answer:**

**Current approach: Cache-aside pattern with eviction**

```java
// Read: Cache-aside
@Cacheable(value = "articles", key = "#id")
public ArticleDto getArticle(Long id) {
    return toDto(articleRepository.findById(id).orElseThrow());
}

// Write: Write-through with eviction
@CacheEvict(value = "articles", key = "#id")
public ArticleDto updateArticle(Long id, ArticleDto dto) {
    Article article = articleRepository.findById(id).orElseThrow();
    article.setTitle(dto.getTitle());
    return toDto(articleRepository.save(article));
}
```

**Consistency challenges:**

1. **Race condition:**
   ```
   T1: Read article from DB (v1)
   T2: Update article in DB (v2)
   T2: Evict cache
   T1: Write to cache (v1) ← STALE!
   ```

2. **Eviction failure:**
   - Redis temporarily unavailable
   - Network partition
   - Cache evict succeeds but DB update fails

**Stronger consistency patterns:**

**Write-behind (async cache update):**
```java
@Transactional
public ArticleDto updateArticle(Long id, ArticleDto dto) {
    Article saved = articleRepository.save(toEntity(dto));

    // Publish event for async cache update
    eventPublisher.publish(new ArticleUpdatedEvent(saved));
    return toDto(saved);
}

@EventListener
@Async
public void onArticleUpdated(ArticleUpdatedEvent event) {
    cache.put("article:" + event.getId(), toDto(event.getArticle()));
}
```

**Change Data Capture (CDC):**
- Use Debezium to stream DB changes
- Cache subscriber updates from change stream
- Guarantees eventual consistency

**Short TTL + stale-while-revalidate:**
```java
@Cacheable(value = "articles", key = "#id", unless = "#result == null")
public ArticleDto getArticle(Long id) {
    return toDto(articleRepository.findById(id).orElseThrow());
}
// TTL: 5 minutes, acceptable staleness for this use case
```

---

### Question 42: Explain the Redis data structures you would use for different features.

**Answer:**

**Current: Simple key-value (Strings)**
```
articles::42 → {serialized ArticleDto}
```

**Advanced use cases:**

**1. Rate limiting (Sorted Sets):**
```
ZADD rate:login:192.168.1.1 {timestamp} {request-id}
ZREMRANGEBYSCORE rate:login:192.168.1.1 0 {window-start}
ZCARD rate:login:192.168.1.1
```
- Score = timestamp, sorted by time
- Remove old entries, count remaining

**2. User sessions (Hashes):**
```
HSET session:abc123 userId "42" role "ADMIN" expiresAt "..."
HGET session:abc123 userId
EXPIRE session:abc123 86400
```
- Multiple fields in one key
- Atomic field updates

**3. Article view counts (Strings with INCR):**
```
INCR article:42:views
GET article:42:views
```
- Atomic increment
- No race conditions

**4. Real-time leaderboard (Sorted Sets):**
```
ZINCRBY article:views:daily 1 "42"  # Increment article 42's views
ZREVRANGE article:views:daily 0 9 WITHSCORES  # Top 10
```

**5. Tag-based article lookup (Sets):**
```
SADD tag:javascript 42 43 44
SADD tag:react 42 45
SINTER tag:javascript tag:react  # Articles with both tags: {42}
```

**6. Pub/Sub for cache invalidation:**
```java
// Publisher (blog-service instance 1)
redisTemplate.convertAndSend("cache:invalidate", "article:42");

// Subscriber (all instances)
@RedisListener(topics = "cache:invalidate")
public void onInvalidate(String key) {
    localCache.evict(key);
}
```

---

### Question 43: How would you implement cache warming?

**Answer:**

Cache warming pre-populates the cache on startup or before traffic spikes:

**1. Startup warming:**

```java
@Component
public class CacheWarmer implements ApplicationRunner {

    @Override
    public void run(ApplicationArguments args) {
        log.info("Warming article cache...");

        // Load most accessed articles
        List<Long> popularIds = analyticsService.getTopArticleIds(100);

        for (Long id : popularIds) {
            try {
                articleService.getArticle(id);  // Triggers @Cacheable
            } catch (Exception e) {
                log.warn("Failed to warm cache for article {}", id);
            }
        }

        log.info("Cache warming complete: {} articles", popularIds.size());
    }
}
```

**2. Scheduled warming:**

```java
@Scheduled(cron = "0 0 6 * * *")  // Every day at 6 AM
public void warmCacheBeforeTraffic() {
    // Pre-cache expected high-traffic content
    List<Article> todaysArticles = articleRepository.findByPublishDateToday();
    for (Article article : todaysArticles) {
        cacheManager.getCache("articles").put(article.getId(), toDto(article));
    }
}
```

**3. Event-driven warming (on cache eviction):**

```java
@CacheEvict(value = "articles", key = "#id")
public void updateArticle(Long id, ArticleDto dto) {
    Article saved = articleRepository.save(toEntity(dto));

    // Immediately re-warm
    cacheManager.getCache("articles").put(id, toDto(saved));
}
```

**4. Lazy warming with read-through:**

```java
@Cacheable(value = "articles", key = "#id", sync = true)
public ArticleDto getArticle(Long id) {
    // sync = true prevents cache stampede on cold cache
    return toDto(articleRepository.findById(id).orElseThrow());
}
```

**Warming strategies comparison:**

| Strategy | When to use |
|----------|-------------|
| Startup | Known popular content, small dataset |
| Scheduled | Predictable traffic patterns |
| Event-driven | Write-heavy with immediate reads |
| Lazy + sync | Unpredictable access patterns |

---

## Architecture & System Design

### Question 44: Why use microservices vs monolith for this application?

**Answer:**

**Current architecture:** Microservices (auth-service + blog-service)

**Reasons for microservices here:**

1. **Independent deployment** - Update auth without touching blog
2. **Technology isolation** - Could use different languages per service
3. **Scaling** - Scale blog-service independently during high traffic
4. **Team autonomy** - Different teams can own different services
5. **Failure isolation** - Auth failure doesn't crash article serving

**Why a monolith might be better:**

1. **Complexity overhead** - Two JVMs, two deployments, distributed debugging
2. **Shared database** - Not truly independent (schema coupling)
3. **Network latency** - Inter-service calls add latency
4. **Team size** - For small teams, monolith is simpler
5. **Transaction management** - Distributed transactions are hard

**This application's situation:**

```
Current trade-offs:
+ Services are cleanly separated (auth vs content)
+ Can scale article reads independently
- Shared database negates some microservice benefits
- No service mesh or distributed tracing
- Simple enough for a well-structured monolith
```

**Recommendation:** For this size, a **modular monolith** might be ideal:
- Single deployable with module boundaries
- Easier local development
- Split to microservices when truly needed (scale, team size)

---

### Question 45: How does the Nginx reverse proxy improve the architecture?

**Answer:**

**Nginx configuration:**

```nginx
upstream auth_service {
    server auth-service:8081;
}

upstream blog_service {
    server blog-service:8082;
}

server {
    listen 80;

    # Frontend static files
    location / {
        root /usr/share/nginx/html;
        try_files $uri $uri/ /index.html;
    }

    # API routing
    location /api/auth/ {
        proxy_pass http://auth_service/auth/;
    }

    location /api/articles {
        proxy_pass http://blog_service/articles;
    }
}
```

**Benefits:**

1. **Single entry point** - Frontend only knows one host (port 8080)
2. **Path-based routing** - Routes to correct service by URL
3. **TLS termination** - HTTPS at edge, HTTP internally
4. **Static file serving** - Efficient serving of React bundle
5. **SPA support** - `try_files` enables client-side routing
6. **Load balancing** - Can add multiple upstream servers
7. **Caching** - Can cache static assets
8. **Security** - Internal services not exposed to internet

**What Nginx handles vs Spring:**

| Concern | Nginx | Spring |
|---------|-------|--------|
| TLS/SSL | ✓ | - |
| Static files | ✓ | - |
| Routing | ✓ | ✓ |
| Auth | - | ✓ |
| Business logic | - | ✓ |
| Rate limiting | ✓ | ✓ |

**Production enhancements:**

```nginx
# Gzip compression
gzip on;
gzip_types text/plain application/json application/javascript;

# Security headers
add_header X-Frame-Options DENY;
add_header X-Content-Type-Options nosniff;

# Connection pooling
upstream blog_service {
    server blog-service:8082;
    keepalive 32;
}
```

---

### Question 46: How would you implement API versioning?

**Answer:**

**Option 1: URL path versioning (Recommended for this app)**

```java
@RestController
@RequestMapping("/api/v1/articles")
public class ArticleControllerV1 {
    @GetMapping
    public Page<ArticleSummaryDto> getArticles() { }
}

@RestController
@RequestMapping("/api/v2/articles")
public class ArticleControllerV2 {
    @GetMapping
    public Page<ArticleSummaryDtoV2> getArticles() {
        // New response format
    }
}
```

Nginx routing:
```nginx
location /api/v1/ {
    proxy_pass http://blog_service_v1/;
}
location /api/v2/ {
    proxy_pass http://blog_service_v2/;
}
```

**Option 2: Header versioning**

```java
@GetMapping(headers = "X-API-Version=1")
public ArticleDto getArticleV1(@PathVariable Long id) { }

@GetMapping(headers = "X-API-Version=2")
public ArticleDtoV2 getArticleV2(@PathVariable Long id) { }
```

**Option 3: Accept header (content negotiation)**

```java
@GetMapping(produces = "application/vnd.blog.v1+json")
public ArticleDto getArticleV1() { }

@GetMapping(produces = "application/vnd.blog.v2+json")
public ArticleDtoV2 getArticleV2() { }
```

**Comparison:**

| Method | Pros | Cons |
|--------|------|------|
| URL path | Simple, cacheable, visible | URL changes for clients |
| Header | Clean URLs | Harder to test, not cacheable |
| Accept header | RESTful purist approach | Complex, poor tooling support |

**Version deprecation strategy:**

```java
@RestController
@RequestMapping("/api/v1/articles")
@Deprecated
public class ArticleControllerV1 {

    @GetMapping
    public ResponseEntity<Page<ArticleDto>> getArticles() {
        return ResponseEntity.ok()
            .header("Deprecation", "version=\"v1\", date=\"2024-06-01\"")
            .header("Sunset", "2024-12-01")
            .body(articleService.getArticles());
    }
}
```

---

### Question 47: How would you add observability (logging, metrics, tracing)?

**Answer:**

**1. Structured Logging (already partially implemented):**

```java
@Slf4j
@RestController
public class ArticleController {

    @GetMapping("/{id}")
    public ArticleDto getArticle(@PathVariable Long id) {
        log.info("Fetching article", Map.of("articleId", id, "userId", getCurrentUserId()));
        // ...
    }
}
```

**Logback configuration for JSON:**
```xml
<appender name="JSON" class="ch.qos.logback.core.ConsoleAppender">
    <encoder class="net.logstash.logback.encoder.LogstashEncoder"/>
</appender>
```

**2. Metrics with Micrometer + Prometheus:**

```java
@Configuration
public class MetricsConfig {

    @Bean
    MeterRegistryCustomizer<MeterRegistry> metricsCommonTags() {
        return registry -> registry.config()
            .commonTags("application", "blog-service");
    }
}

@Service
public class ArticleService {
    private final Counter articleCreatedCounter;
    private final Timer articleFetchTimer;

    public ArticleService(MeterRegistry registry) {
        this.articleCreatedCounter = registry.counter("articles.created");
        this.articleFetchTimer = registry.timer("articles.fetch");
    }

    public ArticleDto getArticle(Long id) {
        return articleFetchTimer.record(() ->
            toDto(articleRepository.findById(id).orElseThrow())
        );
    }
}
```

**Expose metrics endpoint:**
```properties
management.endpoints.web.exposure.include=health,info,metrics,prometheus
management.metrics.export.prometheus.enabled=true
```

**3. Distributed Tracing with OpenTelemetry:**

```xml
<dependency>
    <groupId>io.opentelemetry</groupId>
    <artifactId>opentelemetry-spring-boot-starter</artifactId>
</dependency>
```

```properties
otel.service.name=blog-service
otel.exporter.otlp.endpoint=http://jaeger:4317
```

**Docker Compose additions:**

```yaml
services:
  prometheus:
    image: prom/prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"

  grafana:
    image: grafana/grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin

  jaeger:
    image: jaegertracing/all-in-one
    ports:
      - "16686:16686"  # UI
      - "4317:4317"    # OTLP
```

---

### Question 48: What would a production deployment look like?

**Answer:**

**Current (development):**
```
Docker Compose → Single host, all services
```

**Production architecture:**

```
                    ┌─────────────────┐
                    │   CloudFlare    │
                    │   (CDN + WAF)   │
                    └────────┬────────┘
                             │
                    ┌────────▼────────┐
                    │  Load Balancer  │
                    │   (AWS ALB)     │
                    └────────┬────────┘
                             │
         ┌───────────────────┼───────────────────┐
         │                   │                   │
    ┌────▼────┐        ┌────▼────┐        ┌────▼────┐
    │ K8s Pod │        │ K8s Pod │        │ K8s Pod │
    │ Nginx   │        │ Nginx   │        │ Nginx   │
    └────┬────┘        └────┬────┘        └────┬────┘
         │                   │                   │
    ┌────▼────┐        ┌────▼────┐        ┌────▼────┐
    │auth-svc │        │auth-svc │        │auth-svc │
    │blog-svc │        │blog-svc │        │blog-svc │
    └────┬────┘        └────┬────┘        └────┬────┘
         │                   │                   │
         └───────────────────┼───────────────────┘
                             │
              ┌──────────────┴──────────────┐
              │                             │
    ┌─────────▼─────────┐         ┌─────────▼─────────┐
    │ RDS PostgreSQL    │         │ ElastiCache Redis │
    │ (Multi-AZ)        │         │ (Cluster mode)    │
    └───────────────────┘         └───────────────────┘
```

**Kubernetes deployment:**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: blog-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: blog-service
  template:
    spec:
      containers:
      - name: blog-service
        image: blog-service:1.0.0
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        readinessProbe:
          httpGet:
            path: /actuator/health/readiness
            port: 8082
        livenessProbe:
          httpGet:
            path: /actuator/health/liveness
            port: 8082
        env:
        - name: JWT_SECRET
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: jwt-secret
```

**Key production concerns:**

| Concern | Solution |
|---------|----------|
| Secrets | K8s Secrets, AWS Secrets Manager |
| TLS | Let's Encrypt, AWS ACM |
| Database | RDS with Multi-AZ, read replicas |
| Cache | ElastiCache Redis cluster |
| CI/CD | GitHub Actions, ArgoCD |
| Monitoring | Prometheus + Grafana, CloudWatch |
| Logging | ELK stack, CloudWatch Logs |

---

### Question 49: How would you handle database migrations in production?

**Answer:**

**Problem with current approach:**
```properties
spring.jpa.hibernate.ddl-auto=update  # Dangerous in production!
```

**Solution: Flyway migrations**

**Setup:**
```xml
<dependency>
    <groupId>org.flywaydb</groupId>
    <artifactId>flyway-core</artifactId>
</dependency>
```

```properties
spring.jpa.hibernate.ddl-auto=validate  # Only validate, don't modify
spring.flyway.enabled=true
spring.flyway.locations=classpath:db/migration
```

**Migration files:**

```sql
-- V1__create_users_table.sql
CREATE TABLE users (
    id BIGSERIAL PRIMARY KEY,
    email VARCHAR(255) NOT NULL UNIQUE,
    password VARCHAR(255) NOT NULL,
    role VARCHAR(50) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- V2__create_articles_table.sql
CREATE TABLE articles (
    id BIGSERIAL PRIMARY KEY,
    title VARCHAR(200) NOT NULL,
    content TEXT NOT NULL,
    tags VARCHAR(100),
    publish_status VARCHAR(50) NOT NULL,
    author_id BIGINT NOT NULL REFERENCES users(id),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- V3__add_article_indexes.sql
CREATE INDEX idx_articles_author ON articles(author_id);
CREATE INDEX idx_articles_title ON articles(title);
```

**Rollback migrations (undo):**
```sql
-- U3__add_article_indexes.sql (undo file)
DROP INDEX idx_articles_author;
DROP INDEX idx_articles_title;
```

**CI/CD integration:**

```yaml
# GitHub Actions
jobs:
  migrate:
    steps:
      - name: Run Flyway migrations
        run: |
          flyway -url=$DB_URL -user=$DB_USER -password=$DB_PASSWORD migrate

      - name: Verify migration
        run: flyway validate
```

**Zero-downtime migration patterns:**

1. **Add column (easy):**
   ```sql
   ALTER TABLE articles ADD COLUMN summary TEXT;
   ```

2. **Rename column (expand-contract):**
   ```sql
   -- Step 1: Add new column
   ALTER TABLE articles ADD COLUMN description TEXT;
   -- Step 2: Deploy code that writes to both
   -- Step 3: Backfill data
   UPDATE articles SET description = summary WHERE description IS NULL;
   -- Step 4: Deploy code that reads from new column
   -- Step 5: Drop old column
   ALTER TABLE articles DROP COLUMN summary;
   ```

---

### Question 50: How would you scale this system to handle 100x current traffic?

**Answer:**

**Scaling strategy by component:**

**1. Frontend (Nginx + React)**
```
Current: Single container
Scaled: CDN (CloudFlare/CloudFront) + multiple Nginx pods

Benefits:
- Static assets cached at edge (global)
- 90%+ of requests never hit origin
- Auto-scaling based on traffic
```

**2. Auth Service**
```
Current: Single instance
Scaled: 3-5 replicas behind load balancer

Bottleneck: Rate limiting in-memory
Solution: Redis-backed rate limiting

@Component
public class RedisRateLimiter {
    public boolean isAllowed(String key) {
        String redisKey = "rate:" + key;
        Long count = redis.opsForValue().increment(redisKey);
        if (count == 1) redis.expire(redisKey, Duration.ofSeconds(60));
        return count <= 5;
    }
}
```

**3. Blog Service**
```
Current: Single instance
Scaled: 10+ replicas with horizontal pod autoscaler

Kubernetes HPA:
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
spec:
  scaleTargetRef:
    name: blog-service
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        averageUtilization: 70
```

**4. Database (PostgreSQL)**
```
Current: Single instance
Scaled:
- Primary for writes
- 2-3 read replicas for reads
- Connection pooling (PgBouncer)

Read/write splitting:
@Bean
@Primary
public DataSource routingDataSource() {
    return new ReadWriteRoutingDataSource(primaryDS, replicaDS);
}
```

**5. Cache (Redis)**
```
Current: Single instance
Scaled: Redis Cluster (6 nodes minimum)
- Automatic sharding across nodes
- 3 masters + 3 replicas for HA
```

**Architecture at scale:**

```
┌──────────────────────────────────────────────────────────────────┐
│                         CloudFlare CDN                           │
│                    (Static assets, WAF, DDoS)                    │
└────────────────────────────┬─────────────────────────────────────┘
                             │
┌────────────────────────────▼─────────────────────────────────────┐
│                    AWS Application Load Balancer                  │
└────────────────────────────┬─────────────────────────────────────┘
                             │
        ┌────────────────────┼────────────────────┐
        │                    │                    │
   ┌────▼────┐          ┌────▼────┐          ┌────▼────┐
   │ Auth x3 │          │Blog x10 │          │Nginx x5 │
   └────┬────┘          └────┬────┘          └─────────┘
        │                    │
        │    ┌───────────────┴───────────────┐
        │    │                               │
   ┌────▼────▼───────┐              ┌────────▼────────┐
   │ PgBouncer Pool  │              │  Redis Cluster  │
   └────────┬────────┘              │  (6 nodes)      │
            │                       └─────────────────┘
   ┌────────▼────────┐
   │   PostgreSQL    │
   │ Primary + 3 Rep │
   └─────────────────┘
```

**Performance targets at 100x:**

| Metric | Current | Target |
|--------|---------|--------|
| Requests/sec | 100 | 10,000 |
| P99 latency | 200ms | 100ms |
| Availability | 99% | 99.9% |
| Error rate | 1% | 0.1% |

**Key optimizations:**
1. **Cache hit rate > 90%** - Warm cache, longer TTLs
2. **Connection pooling** - Reuse DB connections
3. **Async processing** - Queue heavy operations
4. **Read replicas** - Distribute read load
5. **Sharding** - If single DB becomes bottleneck

---

## Summary

This document covered 50 interview questions across:

- **Frontend (10)**: React patterns, security, state management
- **Auth Service (10)**: JWT, Spring Security, rate limiting
- **Blog Service (10)**: Caching, authorization, JPA patterns
- **Database (7)**: Schema design, transactions, indexes
- **Redis (6)**: Caching strategies, consistency, scaling
- **Architecture (7)**: Microservices, observability, scaling

Each answer provides practical implementation details from this specific codebase while explaining underlying concepts applicable to any full-stack application.
